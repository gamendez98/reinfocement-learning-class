{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorítmo de Q-Learning\n",
    "\n",
    "En este ejercicio vamos a probar el algorítmo de Q-learning como un representatnte de los métodos off-policy. Nuestro objetivo, es evaluar el algoritmo sobre distintos ambientes. Para cada uno de los ambientes deben ejecutar un agente de Q-learning en el ambiente, evaluar su ejecución y validar la efectividad del aprendizaje del agente entrenado sobre el ambiente.\n",
    "\n",
    "\n",
    "## Gridworld\n",
    "\n",
    "Sobre el ambiente de Gridworld que hemos venido utilizando, ejecute el algoritmo de Q-learning. Debe ejecutar el algoritmo hasta su convergencia y entregar tanto la política resultado y la Q-tabla.\n",
    "\n",
    "## Laberinto de cuartos \n",
    "\n",
    "El ambiente del laberinto de cuartos consiste en una cuadricula con 4 cuartos como se muestra a continuación.\n",
    "\n",
    "![rooms](https://raw.githubusercontent.com/FLAGlab/isis4222-rl/386f826f02646122e1d7a86fd961ce072fbf5a03/week7/img/four-rooms.png)\n",
    "\n",
    "Para este ambiente queremos que el agente aprenda a salir por el cuarto superior izquierdo en la menor cantidad de pasos posible. La única restricción de este ambiente es que al final de cada episodio el agente comienza nuevamente en cualquier posicón valida del laberinto. Usted debe definir los parametros ($\\alpha, \\gamma, \\epsilon$, recompensa) para asegurar el comportamiento del agente\n",
    "\n",
    "## Taxi\n",
    "\n",
    "El ambiente de taxi consiste en una cuadrícula de `5x5`, con 4 estaciones (`R`, `G`,`Y`, `B`), como se muestra en la figura. El taxi puede moverse libremente entre las casillas de la cuadrícula. sin embargo, no puede atravesar por los separadores (las lines más gruesas en la figura).\n",
    "\n",
    "![taxi](https://raw.githubusercontent.com/FLAGlab/isis4222-rl/386f826f02646122e1d7a86fd961ce072fbf5a03/week7/img/Taxi.png)\n",
    "\n",
    "El taxi (i.e., el agente) se mueve por el ambiente buscando recoger un pasajero. Los pasajeros aparecen aleatoriamente en alguno de los paraderos (uno a la vez) y deben llegar a su destino (algún otro paradero).\n",
    "\n",
    "Las acciones del agente corresponden a los movimientos del agente en el tablero y las acciones para recoger y dejar pasajeros. \n",
    "Tratar de recoger o dejar un pasajero en un lugar indebido o cuando no hay pasajero, son consideradas malas accciones del agente y deben ser penalizadas (tienen una recompenza de -10). Para asegurar que el agente efectivamente recoge pasajeros, debemos darle una recompensa de 1 a la acción. Efectivamente dejar al pasajero tiene una recompensa de 5. \n",
    "\n",
    "Implemente el algoritmo de Q-learning (defina sus propios parámetros) para el aprendizaje del agente."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:22:43.964044Z",
     "start_time": "2024-10-12T18:22:43.793142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "from assignment_q_learning.q_learning_agent import QLearningAgent\n",
    "from assignment_q_learning.taxi_environment import TaxiEnvironmentWorld, Station, TaxiState\n",
    "from assignment_q_learning.walled_environment import WalledEnvironmentWorld"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:01:20.093570Z",
     "start_time": "2024-10-12T17:01:19.894903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "walls = [((0, 4), (0, 5)), ((1, 4), (1, 5)), ((3, 4), (3, 5)), ((4, 4), (4, 5)), ((4, 0), (5, 0)), ((4, 1), (5, 1)),\n",
    "         ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 8), (5, 8)), ((4, 9), (5, 9)),\n",
    "         ((5, 4), (5, 5)), ((6, 4), (6, 5)), ((8, 4), (8, 5)), ((9, 4), (9, 5))]\n",
    "\n",
    "board = [[' ' for i in range(10)] for j in range(10)]\n",
    "board[0][2] = '+100'\n",
    "\n",
    "wall_environment = WalledEnvironmentWorld(board=board, walls=walls, terminal_states=[(2, 0)])\n",
    "\n",
    "print(wall_environment)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1     2  3  4  5  6  7  8  9\n",
      "0         +100                     \n",
      "1                                  \n",
      "2   C                              \n",
      "3                                  \n",
      "4                                  \n",
      "5                                  \n",
      "6                                  \n",
      "7                                  \n",
      "8                                  \n",
      "9                                  \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:01:22.705614Z",
     "start_time": "2024-10-12T17:01:22.702314Z"
    }
   },
   "cell_type": "code",
   "source": "q_agent_walls = QLearningAgent(wall_environment, learning_rate=0.8, discount_factor=0.9, epsilon=0.5)",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:01:32.235840Z",
     "start_time": "2024-10-12T17:01:24.052187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "q_agent_walls.iterate_learning(1000000)\n",
    "q_agent_walls.print_policy()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:08<00:00, 122358.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1     2     3     4      5      6     7     8     9\n",
      "0  right  right  None  left  left   down   down  down  down  down\n",
      "1     up     up    up    up    up   down   down  down  down  down\n",
      "2     up     up    up    up    up   left   left  left  left  left\n",
      "3     up     up    up    up    up     up     up    up    up    up\n",
      "4     up     up    up    up    up     up     up    up    up    up\n",
      "5  right  right    up  left  left  right  right    up  left  left\n",
      "6     up     up    up    up    up   down     up    up    up    up\n",
      "7     up     up    up    up    up   left   left    up    up    up\n",
      "8     up     up    up    up    up     up     up    up    up    up\n",
      "9     up     up    up    up    up     up     up    up    up    up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T18:22:49.332649Z",
     "start_time": "2024-10-12T18:22:49.328554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "taxi_walls = [\n",
    "    ((1, 0), (2, 0)), ((1, 1), (2, 1)),\n",
    "    ((0, 3), (1, 3)), ((0, 4), (1, 4)),\n",
    "    ((2, 3), (3, 3)), ((2, 4), (3, 4)),\n",
    "]\n",
    "\n",
    "r, g, y, b = (\n",
    "    Station((0, 0), 'R'),\n",
    "    Station((4, 0), 'G'),\n",
    "    Station((0, 4), 'Y'),\n",
    "    Station((3, 4), 'B')\n",
    ")\n",
    "\n",
    "stations = [r, g, y, b]\n",
    "\n",
    "taxi_world = TaxiEnvironmentWorld(board=[[' '] * 5] * 5, walls=taxi_walls, stations=stations)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:00:30.831930Z",
     "start_time": "2024-10-12T19:00:30.829340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "q_agent_taxi = QLearningAgent(taxi_world, learning_rate=0.8, discount_factor=0.9, epsilon=0.5,\n",
    "                              learning_rate_decay=0.1 ** (1 / 2500000))"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:01:19.325363Z",
     "start_time": "2024-10-12T19:00:41.321843Z"
    }
   },
   "cell_type": "code",
   "source": "q_agent_taxi.iterate_learning(5000000)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000000/5000000 [00:38<00:00, 131578.68it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:01:21.097853Z",
     "start_time": "2024-10-12T19:01:21.093763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_taxi_policy(q_agent, passenger_station, on_passenger=False):\n",
    "    world = q_agent.world\n",
    "    policy_matrix = [[None for y_ in range(world.num_rows)] for x in range(world.num_cols)]\n",
    "    for y in range(world.num_rows):\n",
    "        for x in range(world.num_cols):\n",
    "            state = TaxiState((x, y), passenger_station, on_passenger)\n",
    "            if state in q_agent_taxi.Q:\n",
    "                action = q_agent.get_opt_action(state)\n",
    "                if action is not None:\n",
    "                    policy_matrix[x][y] = action.value\n",
    "            else:\n",
    "                policy_matrix[x][y] = None\n",
    "\n",
    "    print(pd.DataFrame(policy_matrix).transpose())"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:01:24.013546Z",
     "start_time": "2024-10-12T19:01:24.008512Z"
    }
   },
   "cell_type": "code",
   "source": "print_taxi_policy(q_agent_taxi, None, False)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1      2      3      4\n",
      "0  down   left  right  right  right\n",
      "1    up   left  right     up     up\n",
      "2    up   left  right   down   left\n",
      "3  down  right  right   down   left\n",
      "4    up     up     up   down   left\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:03:26.211008Z",
     "start_time": "2024-10-12T19:03:26.205140Z"
    }
   },
   "cell_type": "code",
   "source": "print_taxi_policy(q_agent_taxi, None, True)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0     1     2       3       4\n",
      "0  pickup  None  None    None  pickup\n",
      "1    None  None  None    None    None\n",
      "2    None  None  None    None    None\n",
      "3    None  None  None    None    None\n",
      "4  pickup  None  None  pickup    None\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T19:03:29.298049Z",
     "start_time": "2024-10-12T19:03:29.290069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for station in stations:\n",
    "    print(f'STATION: {station}_____________')\n",
    "    print_taxi_policy(q_agent_taxi, station, False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION: Station(position=(0, 0), name='R')_____________\n",
      "         0     1     2     3     4\n",
      "0  dropoff  left  down  down  left\n",
      "1       up  left  down  down    up\n",
      "2       up    up  left  left  left\n",
      "3       up    up    up    up    up\n",
      "4       up    up    up    up  left\n",
      "STATION: Station(position=(4, 0), name='G')_____________\n",
      "       0      1      2      3        4\n",
      "0   down   down  right  right  dropoff\n",
      "1  right   down  right  right       up\n",
      "2  right  right  right     up       up\n",
      "3     up     up     up  right       up\n",
      "4     up     up     up     up       up\n",
      "STATION: Station(position=(0, 4), name='Y')_____________\n",
      "         0     1     2     3     4\n",
      "0     down  left  down  down  down\n",
      "1     down  left  down  down  left\n",
      "2     down  left  left  left  left\n",
      "3     down    up    up    up  left\n",
      "4  dropoff    up    up    up  left\n",
      "STATION: Station(position=(3, 4), name='B')_____________\n",
      "       0      1      2        3     4\n",
      "0   down   down  right    right  down\n",
      "1  right   down  right     down  down\n",
      "2  right  right  right     down  down\n",
      "3     up     up     up     down  down\n",
      "4     up     up     up  dropoff  left\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
