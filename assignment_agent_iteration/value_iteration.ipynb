{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteración de Valores\n",
    "\n",
    "En este ejercicio vamos a implementar el primer método para solucionar Procesos de Decisión de Markov (MDPs). El método a implementar es la iteración de valores.\n",
    "\n",
    "La iteración de valores esta basada en la fórmula:\n",
    "\n",
    "![value_iteration](https://raw.githubusercontent.com/FLAGlab/isis4222-rl/a502e264157729fcb8cc00d484e4a8e8e4734a15/week4/img/value_iteration.png)\n",
    "\n",
    "Para resolver los MDPs crearemos un archivo `value_iteration.py` el cual utilizaremos para solucionar el ambiente de Gridworld.\n",
    "\n",
    "**Task 1**\n",
    "1. Implemente la classe `ValueIteration` con cuatro atributos:\n",
    "    - `mdp` que corresponde al MDP a resolver (e.g., Gridworld) \n",
    "    - `discount` que corresponde al factor de decuento a utilizar, `0.9` por defecto.\n",
    "    - `iterations` que corresponde a el número de iteraciones a realizar.\n",
    "    - `values` que corresponde a los valores calculados para los estados del MDP.\n",
    "\n",
    "2. El comportamiento del agente (de iteración de valores) esta dado por los métodos:\n",
    "    - `run_value_iteration` que no recibe ningún parámatetro y ejecuta el algoritmo de iteración de valores para la solución del MDP.\n",
    "    - `get_value` recibe un estado y retorna el valor correspondiende para dicho estado.\n",
    "    - `compute_qvalue_from_values` recibe un estado y una acción y calcula el q valor correspondiente.\n",
    "    - `compute_action_from_values` que calcula la acción a tomar (como la acción con el mejor valor en `values`) para un estado dado\n",
    "    - `get_action` retorna la acción a tomar dado un estado (directamente como la acción de la política, sin exploración)\n",
    "    - `get_qvalue` retorna el q valor dado un estado y una acción\n",
    "    - `get_policy` que retorna la acción a tomar para un estado (como `get_action`). Si el estado no tiene una acción asociada a él, retorne `None`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega\n",
    "\n",
    "Para esta tarea debe entregar: \n",
    "- La implementación de la iteración de valores para solucionar MDPs (`value_iteration.py`).\n",
    "- Un documento de análisis respondiendo a las siguientes preguntas (con screenshots de la solución y las explicaciones correspondientes del comportamiento observado).\n",
    "  -\tEjecute su implementación de iteración de valores para 5, 10, 15, 20, 30, 50 iteraciones, sobre el ambiente de gridworld. ¿Cuando convergen los valores o las acciones?\n",
    "  -\tEjecute su implementación sobre el ambiente del puente (i.e., Bridge) durante 10 iteraciones. Qué resultado observa si kodifica el valor de descuento de 0.9 a 0.1. Explique si los resultados cambian y porqué. \n",
    "  \n",
    "  Recuerde que el ambiente del puente se define con la matriz de `3x7` donde las filas 1 y 3 tienen recompensa -100 entre las columnas 2 y 6. La fila 2 corresponde a el puente, con entrada en la casilla `(2,1)` y salida en la casilla `(2,7)` con recompensa 100, como se muestra en la figura\n",
    "\n",
    "  ![bridge](https://raw.githubusercontent.com/FLAGlab/isis4222-rl/a502e264157729fcb8cc00d484e4a8e8e4734a15/week4/img/bridge.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:51:55.031743Z",
     "start_time": "2024-09-09T19:51:54.783370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1  2  3  4   5   6  7  8  9\n",
      "0  SC                             \n",
      "1                                 \n",
      "2      #  #  #  #       #  #  #   \n",
      "3               #                 \n",
      "4               #  -1             \n",
      "5               #  +1             \n",
      "6               #                 \n",
      "7               #  -1  -1         \n",
      "8                                 \n",
      "9                                 \n",
      "\n",
      "\n",
      "\n",
      "    0     1     2     3     4     5     6\n",
      "0   #  -100  -100  -100  -100  -100     #\n",
      "1  +1    SC                          +100\n",
      "2   #  -100  -100  -100  -100  -100     #\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from assignment_agent_iteration.grid_world import EnvironmentWorld\n",
    "from assignment_agent_iteration.value_iteration import ValueIteration\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "grid_world = EnvironmentWorld([\n",
    "    ['S'] + [' '] * 9,\n",
    "    [' '] * 10,\n",
    "    [' ', '#', '#', '#', '#', ' ', '#', '#', '#', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', '-1', ' ', ' ', ' ', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', '+1', ' ', ' ', ' ', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', '-1', '-1', ' ', ' ', ' '],\n",
    "    [' '] * 10,\n",
    "    [' '] * 10\n",
    "])\n",
    "\n",
    "bridge_world = EnvironmentWorld([\n",
    "    ['#', '-100', '-100', '-100', '-100', '-100', '#'],\n",
    "    ['+1', 'S', ' ', ' ', ' ', ' ', '+100'],\n",
    "    ['#', '-100', '-100', '-100', '-100', '-100', '#'],\n",
    "])\n",
    "\n",
    "print(grid_world)\n",
    "print('\\n\\n')\n",
    "print(bridge_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:52:26.657173Z",
     "start_time": "2024-09-09T19:52:26.654065Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_value_iteration(value_iteration, previous_values=None, previous_iterations=None):\n",
    "    print(f'\\n{\"_\" * 8} iterations={value_iteration.iterations} discount={value_iteration.discount} {\"_\" * 8}')\n",
    "    current_value = pd.DataFrame(value_iteration.values)\n",
    "    if previous_values is not None:\n",
    "        average_square_error = ((current_value - previous_values) ** 2).fillna(0).values.sum() / (\n",
    "                current_value.count().sum() * (value_iteration.iterations - previous_iterations))\n",
    "        print(f'average_square_error (measure of convergence) = {average_square_error}')\n",
    "    print(\"___values___\")\n",
    "    print(value_iteration)\n",
    "    print(\"___policy___\")\n",
    "    print(value_iteration.get_full_policy().map(lambda action: action.name if action else 'NONE'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:52:37.769563Z",
     "start_time": "2024-09-09T19:52:31.449424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________ iterations=5 discount=0.9 ________\n",
      "___values___\n",
      "     0    1    2    3    4         5         6         7         8         9\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "1  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "2  0.0  NaN  NaN  NaN  NaN  0.073732       NaN       NaN       NaN  0.000000\n",
      "3  0.0  0.0  0.0  0.0  NaN  0.270407  0.539200  0.403257  0.243258  0.000000\n",
      "4  0.0  0.0  0.0  0.0  NaN  1.714597  1.089359  0.822692  0.380470  0.177867\n",
      "5  0.0  0.0  0.0  0.0  NaN  2.064785  1.985762  1.156169  0.652458  0.223725\n",
      "6  0.0  0.0  0.0  0.0  NaN  2.138855  1.587304  1.094122  0.576696  0.290805\n",
      "7  0.0  0.0  0.0  0.0  NaN  0.791830  0.795399  0.464834  0.315038  0.000000\n",
      "8  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.193870  0.000000  0.000000\n",
      "9  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000  0.000000  0.000000\n",
      "___policy___\n",
      "    0     1     2     3     4      5      6     7     8     9\n",
      "0  UP    UP    UP    UP    UP     UP     UP    UP    UP    UP\n",
      "1  UP    UP    UP    UP    UP   DOWN     UP    UP    UP    UP\n",
      "2  UP  NONE  NONE  NONE  NONE   DOWN   NONE  NONE  NONE    UP\n",
      "3  UP    UP    UP    UP  NONE  RIGHT   DOWN  DOWN  DOWN  DOWN\n",
      "4  UP    UP    UP    UP  NONE   DOWN   DOWN  DOWN  DOWN  DOWN\n",
      "5  UP    UP    UP    UP  NONE   DOWN   LEFT  LEFT  LEFT  LEFT\n",
      "6  UP    UP    UP    UP  NONE     UP   LEFT  LEFT  LEFT  LEFT\n",
      "7  UP    UP    UP    UP  NONE     UP     UP    UP  LEFT  LEFT\n",
      "8  UP    UP    UP    UP    UP  RIGHT  RIGHT    UP  LEFT    UP\n",
      "9  UP    UP    UP    UP    UP     UP     UP    UP    UP    UP\n",
      "\n",
      "________ iterations=10 discount=0.9 ________\n",
      "average_square_error (measure of convergence) = 0.046763275951541804\n",
      "___values___\n",
      "     0         1         2         3         4         5         6         7         8         9\n",
      "0  0.0  0.000000  0.008464  0.036399  0.097282  0.176227  0.093896  0.029628  0.020628  0.050707\n",
      "1  0.0  0.003386  0.022008  0.079527  0.197791  0.390755  0.175804  0.065560  0.057583  0.158453\n",
      "2  0.0       NaN       NaN       NaN       NaN  0.751662       NaN       NaN       NaN  0.363689\n",
      "3  0.0  0.000000  0.000000  0.000000       NaN  1.128226  1.385127  1.265964  0.953649  0.629377\n",
      "4  0.0  0.000000  0.000000  0.000000       NaN  2.618832  2.013298  1.677404  1.215475  0.792209\n",
      "5  0.0  0.000000  0.000000  0.000000       NaN  2.974861  2.877964  2.064287  1.441392  0.959687\n",
      "6  0.0  0.000000  0.000000  0.000000       NaN  3.024418  2.507258  1.955347  1.449102  1.003379\n",
      "7  0.0  0.000000  0.000000  0.008902       NaN  1.699479  1.632315  1.344398  1.083887  0.810478\n",
      "8  0.0  0.000000  0.008902  0.032619  0.144581  0.362073  0.501559  0.867268  0.709333  0.525207\n",
      "9  0.0  0.000000  0.000000  0.017247  0.062721  0.206043  0.330761  0.515707  0.389697  0.288115\n",
      "___policy___\n",
      "       0      1      2      3      4      5      6     7      8     9\n",
      "0     UP  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   DOWN  DOWN  RIGHT  DOWN\n",
      "1  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   LEFT  LEFT  RIGHT  DOWN\n",
      "2     UP   NONE   NONE   NONE   NONE   DOWN   NONE  NONE   NONE  DOWN\n",
      "3     UP     UP     UP     UP   NONE  RIGHT   DOWN  DOWN   DOWN  DOWN\n",
      "4     UP     UP     UP     UP   NONE   DOWN   DOWN  DOWN   DOWN  DOWN\n",
      "5     UP     UP     UP     UP   NONE   DOWN   LEFT  LEFT   LEFT  LEFT\n",
      "6     UP     UP     UP   DOWN   NONE     UP   LEFT  LEFT   LEFT  LEFT\n",
      "7     UP     UP  RIGHT   DOWN   NONE     UP     UP    UP   LEFT  LEFT\n",
      "8     UP  RIGHT  RIGHT  RIGHT  RIGHT     UP  RIGHT    UP   LEFT  LEFT\n",
      "9     UP     UP     UP  RIGHT     UP     UP     UP    UP   LEFT    UP\n",
      "\n",
      "________ iterations=15 discount=0.9 ________\n",
      "average_square_error (measure of convergence) = 0.02778074786008019\n",
      "___values___\n",
      "          0         1         2         3         4         5         6         7         8         9\n",
      "0  0.052066  0.113629  0.202782  0.316540  0.443502  0.565497  0.428148  0.270081  0.231550  0.316632\n",
      "1  0.059424  0.142093  0.256404  0.413250  0.613852  0.860211  0.561512  0.345993  0.347460  0.525696\n",
      "2  0.023400       NaN       NaN       NaN       NaN  1.280174       NaN       NaN       NaN  0.838343\n",
      "3  0.006454  0.001373  0.000870  0.001838       NaN  1.659266  1.918320  1.796856  1.483007  1.132405\n",
      "4  0.001296  0.001456  0.003562  0.009840       NaN  3.151364  2.545097  2.211240  1.742481  1.308503\n",
      "5  0.002146  0.005975  0.017249  0.030711       NaN  3.506685  3.411077  2.595790  1.973167  1.474839\n",
      "6  0.007353  0.024464  0.049720  0.083520       NaN  3.557544  3.038716  2.489124  1.978015  1.527440\n",
      "7  0.022510  0.056741  0.114829  0.182295       NaN  2.229233  2.164335  1.871239  1.613233  1.326138\n",
      "8  0.033133  0.088484  0.190328  0.350415  0.572384  0.870512  0.977129  1.388210  1.218284  1.033270\n",
      "9  0.023093  0.067786  0.153635  0.284656  0.460485  0.670624  0.795750  0.999545  0.872855  0.754713\n",
      "___policy___\n",
      "       0      1      2      3      4      5      6     7      8     9\n",
      "0  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   DOWN  LEFT  RIGHT  DOWN\n",
      "1  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   LEFT  LEFT  RIGHT  DOWN\n",
      "2     UP   NONE   NONE   NONE   NONE   DOWN   NONE  NONE   NONE  DOWN\n",
      "3     UP   LEFT   DOWN   DOWN   NONE  RIGHT   DOWN  DOWN   DOWN  DOWN\n",
      "4     UP   DOWN  RIGHT   DOWN   NONE   DOWN   DOWN  DOWN   DOWN  DOWN\n",
      "5  RIGHT  RIGHT  RIGHT   DOWN   NONE   DOWN   LEFT  LEFT   LEFT  LEFT\n",
      "6  RIGHT  RIGHT  RIGHT   DOWN   NONE     UP   LEFT  LEFT   LEFT  LEFT\n",
      "7  RIGHT  RIGHT  RIGHT   DOWN   NONE     UP     UP    UP   LEFT  LEFT\n",
      "8  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT     UP  RIGHT    UP   LEFT  LEFT\n",
      "9  RIGHT  RIGHT  RIGHT  RIGHT     UP     UP     UP    UP   LEFT    UP\n",
      "\n",
      "________ iterations=20 discount=0.9 ________\n",
      "average_square_error (measure of convergence) = 0.0138559001331647\n",
      "___values___\n",
      "          0         1         2         3         4         5         6         7         8         9\n",
      "0  0.230371  0.341906  0.462872  0.596503  0.734685  0.862290  0.715778  0.536661  0.483691  0.581800\n",
      "1  0.229246  0.378765  0.525809  0.703431  0.915754  1.168333  0.856783  0.619961  0.622197  0.817876\n",
      "2  0.146033       NaN       NaN       NaN       NaN  1.594440       NaN       NaN       NaN  1.149264\n",
      "3  0.074876  0.039386  0.036893  0.048169       NaN  1.973646  2.232602  2.111282  1.797178  1.445936\n",
      "4  0.041436  0.050762  0.072202  0.095770       NaN  3.465685  2.859468  2.525527  2.056888  1.621966\n",
      "5  0.068240  0.101686  0.137058  0.173399       NaN  3.821046  3.725377  2.910192  2.287397  1.788810\n",
      "6  0.119071  0.174207  0.231673  0.285526       NaN  3.871839  3.353103  2.803403  2.292435  1.841277\n",
      "7  0.170839  0.256008  0.349636  0.438122       NaN  2.543599  2.478522  2.185597  1.927303  1.640199\n",
      "8  0.197859  0.310946  0.457152  0.642562  0.878350  1.182299  1.287478  1.701638  1.531829  1.345852\n",
      "9  0.183792  0.287035  0.416546  0.573962  0.762424  0.979367  1.103335  1.310985  1.182726  1.064905\n",
      "___policy___\n",
      "       0      1      2      3      4      5      6     7      8     9\n",
      "0  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   DOWN  LEFT  RIGHT  DOWN\n",
      "1  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   LEFT  LEFT  RIGHT  DOWN\n",
      "2     UP   NONE   NONE   NONE   NONE   DOWN   NONE  NONE   NONE  DOWN\n",
      "3     UP   LEFT   DOWN   DOWN   NONE  RIGHT   DOWN  DOWN   DOWN  DOWN\n",
      "4     UP  RIGHT  RIGHT   DOWN   NONE   DOWN   DOWN  DOWN   DOWN  DOWN\n",
      "5  RIGHT  RIGHT  RIGHT   DOWN   NONE   DOWN   LEFT  LEFT   LEFT  LEFT\n",
      "6  RIGHT  RIGHT  RIGHT   DOWN   NONE     UP   LEFT  LEFT   LEFT  LEFT\n",
      "7  RIGHT  RIGHT  RIGHT   DOWN   NONE     UP     UP    UP   LEFT  LEFT\n",
      "8  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT     UP  RIGHT    UP   LEFT  LEFT\n",
      "9  RIGHT  RIGHT  RIGHT  RIGHT     UP     UP     UP    UP   LEFT    UP\n",
      "\n",
      "________ iterations=30 discount=0.9 ________\n",
      "average_square_error (measure of convergence) = 0.007898787100505436\n",
      "___values___\n",
      "          0         1         2         3         4         5         6         7         8         9\n",
      "0  0.500186  0.625473  0.751434  0.887700  1.027215  1.155492  1.007732  0.825619  0.769561  0.869922\n",
      "1  0.492866  0.663574  0.815651  0.995926  1.209605  1.462864  1.149713  0.909867  0.912247  1.110411\n",
      "2  0.391741       NaN       NaN       NaN       NaN  1.889656       NaN       NaN       NaN  1.444373\n",
      "3  0.281619  0.221311  0.223146  0.243813       NaN  2.268859  2.527819  2.406494  2.092399  1.741116\n",
      "4  0.229165  0.259666  0.292964  0.327048       NaN  3.760901  3.154681  2.820745  2.352099  1.917171\n",
      "5  0.299645  0.345560  0.390027  0.433186       NaN  4.116260  4.020594  3.205404  2.582616  2.084006\n",
      "6  0.376128  0.442214  0.505961  0.563956       NaN  4.167057  3.648315  3.098621  2.587646  2.136490\n",
      "7  0.441269  0.536677  0.635627  0.726551       NaN  2.838809  2.773740  2.480805  2.222522  1.935396\n",
      "8  0.472138  0.595926  0.747639  0.935794  1.172820  1.477365  1.582405  1.996835  1.826998  1.641024\n",
      "9  0.457733  0.571650  0.706729  0.866851  1.056638  1.274148  1.398153  1.606015  1.477729  1.359920\n",
      "___policy___\n",
      "       0      1      2      3      4      5      6     7      8     9\n",
      "0  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   DOWN  LEFT  RIGHT  DOWN\n",
      "1  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   LEFT  LEFT  RIGHT  DOWN\n",
      "2     UP   NONE   NONE   NONE   NONE   DOWN   NONE  NONE   NONE  DOWN\n",
      "3     UP   DOWN   DOWN   DOWN   NONE  RIGHT   DOWN  DOWN   DOWN  DOWN\n",
      "4   DOWN  RIGHT  RIGHT   DOWN   NONE   DOWN   DOWN  DOWN   DOWN  DOWN\n",
      "5  RIGHT  RIGHT  RIGHT   DOWN   NONE   DOWN   LEFT  LEFT   LEFT  LEFT\n",
      "6  RIGHT  RIGHT  RIGHT   DOWN   NONE     UP   LEFT  LEFT   LEFT  LEFT\n",
      "7  RIGHT  RIGHT  RIGHT   DOWN   NONE     UP     UP    UP   LEFT  LEFT\n",
      "8  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT     UP  RIGHT    UP   LEFT  LEFT\n",
      "9  RIGHT  RIGHT  RIGHT  RIGHT     UP     UP     UP    UP   LEFT    UP\n",
      "\n",
      "________ iterations=50 discount=0.9 ________\n",
      "average_square_error (measure of convergence) = 0.0009600269272941565\n",
      "___values___\n",
      "          0         1         2         3         4         5         6         7         8         9\n",
      "0  0.638596  0.764177  0.890192  1.026486  1.166014  1.294298  1.146525  0.964378  0.908280  1.008668\n",
      "1  0.631067  0.802292  0.954423  1.134726  1.348418  1.601684  1.288516  1.048637  1.051019  1.249211\n",
      "2  0.529460       NaN       NaN       NaN       NaN  2.028482       NaN       NaN       NaN  1.583200\n",
      "3  0.418129  0.357444  0.359383  0.380334       NaN  2.407685  2.666646  2.545321  2.231225  1.879943\n",
      "4  0.366240  0.396853  0.430463  0.464799       NaN  3.899727  3.293508  2.959572  2.490925  2.055997\n",
      "5  0.437621  0.483731  0.528336  0.571600       NaN  4.255087  4.159420  3.344231  2.721443  2.222832\n",
      "6  0.514598  0.580797  0.644606  0.702641       NaN  4.305883  3.787142  3.237448  2.726473  2.275317\n",
      "7  0.579909  0.675405  0.774395  0.865336       NaN  2.977636  2.912567  2.619631  2.361348  2.074222\n",
      "8  0.610816  0.734691  0.886442  1.074612  1.311644  1.616191  1.721231  2.135662  1.965824  1.779850\n",
      "9  0.596410  0.710414  0.845530  1.005668  1.195461  1.412974  1.536979  1.744842  1.616556  1.498746\n",
      "___policy___\n",
      "       0      1      2      3      4      5      6     7      8     9\n",
      "0  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   DOWN  LEFT  RIGHT  DOWN\n",
      "1  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT   DOWN   LEFT  LEFT  RIGHT  DOWN\n",
      "2     UP   NONE   NONE   NONE   NONE   DOWN   NONE  NONE   NONE  DOWN\n",
      "3     UP   DOWN   DOWN   DOWN   NONE  RIGHT   DOWN  DOWN   DOWN  DOWN\n",
      "4   DOWN  RIGHT  RIGHT   DOWN   NONE   DOWN   DOWN  DOWN   DOWN  DOWN\n",
      "5  RIGHT  RIGHT  RIGHT   DOWN   NONE   DOWN   LEFT  LEFT   LEFT  LEFT\n",
      "6  RIGHT  RIGHT  RIGHT   DOWN   NONE     UP   LEFT  LEFT   LEFT  LEFT\n",
      "7  RIGHT  RIGHT  RIGHT   DOWN   NONE     UP     UP    UP   LEFT  LEFT\n",
      "8  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT     UP  RIGHT    UP   LEFT  LEFT\n",
      "9  RIGHT  RIGHT  RIGHT  RIGHT     UP     UP     UP    UP   LEFT    UP\n"
     ]
    }
   ],
   "source": [
    "iteration_numbers = [5, 10, 15, 20, 30, 50]\n",
    "previous_values = None\n",
    "previous_iterations = None\n",
    "for iteration_number in iteration_numbers:\n",
    "    value_iteration = ValueIteration(grid_world, iterations=iteration_number, discount=0.9)\n",
    "    value_iteration.run_value_iteration()\n",
    "    print_value_iteration(value_iteration, previous_values, previous_iterations)\n",
    "    previous_values = pd.DataFrame(value_iteration.values)\n",
    "    previous_iterations = iteration_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergencia de política y valores\n",
    "\n",
    "En este caso podemos observar que entre las iteraciones 30 y 50 la política converge a su estado final; Sin embargo, al observar los cambios en los valores podemos ver que estos fueron lentos en las últimas iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:53:38.937203Z",
     "start_time": "2024-09-09T19:53:38.744715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________ iterations=10 discount=0.9 ________\n",
      "___values___\n",
      "          0           1           2           3           4           5           6\n",
      "0       NaN -115.596189 -100.334199    1.791989  126.260944  255.750562         NaN\n",
      "1  6.861894  -62.756976   -8.971765  118.124531  283.356827  497.878666  686.189404\n",
      "2       NaN -107.159597  -61.179133   49.405868  182.983836  309.567928         NaN\n",
      "___policy___\n",
      "      0     1      2      3      4      5     6\n",
      "0  NONE  DOWN  RIGHT  RIGHT  RIGHT   DOWN  NONE\n",
      "1  DOWN  LEFT  RIGHT  RIGHT  RIGHT  RIGHT    UP\n",
      "2  NONE    UP     UP     UP     UP     UP  NONE\n",
      "\n",
      "________ iterations=10 discount=0.1 ________\n",
      "___values___\n",
      "          0          1          2          3          4          5           6\n",
      "0       NaN -43.601096 -43.755878 -43.755017 -43.514521 -39.550402         NaN\n",
      "1  1.111111 -30.950875 -33.504777 -33.413169 -29.445417  35.842294  111.111111\n",
      "2       NaN -43.605918 -43.760200 -43.743728 -43.383354 -39.426523         NaN\n",
      "___policy___\n",
      "      0     1     2      3      4      5     6\n",
      "0  NONE  DOWN  DOWN   DOWN   DOWN   DOWN  NONE\n",
      "1  DOWN  LEFT  LEFT  RIGHT  RIGHT  RIGHT    UP\n",
      "2  NONE    UP    UP     UP     UP     UP  NONE\n"
     ]
    }
   ],
   "source": [
    "value_iteration_09 = ValueIteration(bridge_world, iterations=10, discount=0.9)\n",
    "value_iteration_09.run_value_iteration()\n",
    "print_value_iteration(value_iteration_09)\n",
    "\n",
    "value_iteration_01 = ValueIteration(bridge_world, iterations=10, discount=0.1)\n",
    "value_iteration_01.run_value_iteration()\n",
    "print_value_iteration(value_iteration_01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efecto de descuento\n",
    "\n",
    "Al reducir el descuento el agente converge de forma más rápida, ya que los valores de `descuento ** t` aproximan `0` de forma más rápida. Adicionalmente, el agente opta por estrategias de más corto plazo, en este caso cuando está del lado izquierdo ignora el 100 del otro lado del puente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
