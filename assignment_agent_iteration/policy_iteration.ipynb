{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteración de Políticas\n",
    "\n",
    "En este ejercicio vamos a implementar el segundo método para solucionar Procesos de Decisión de Markov (MDPs). El método a implementar es la iteración de políticas.\n",
    "\n",
    "La iteración de políticas esta basada en la fórmula:\n",
    "\n",
    "![policy_iteration](https://raw.githubusercontent.com/FLAGlab/isis4222-rl/a502e264157729fcb8cc00d484e4a8e8e4734a15/week4/img/policy.png)\n",
    "\n",
    "Para resolver los MDPs crearemos un archivo `value_iteration.py` el cual utilizaremos para solucionar el ambiente de Gridworld.\n",
    "\n",
    "**Task 2**\n",
    "1.\tImplemente la classe `PolicyIteration` basada en `ValueIteration`, implementada anteriormente. Teniendo en cuenta los cambios relevantes que deba implementar. Tenga en cuenta que tanto `policy_evaluation` como `policty_iteration` deben ser funciones independientes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega\n",
    "\n",
    "Para esta tarea debe entregar: \n",
    "- La implementación de la iteración de políticas para solucionar MDPs (`policy_iteration.py`).\n",
    "- Un documento de análisis respondiendo a las siguientes preguntas (con screenshots de la solución y las explicaciones correspondientes del comportamiento observado).\n",
    "  -\tEjecute su implementación de iteración de políticas sobre Gridworld y Bridge. ¿Cuando convergen las políticas?\n",
    "  -\tPruebe la implementación sobre el ambiente de Bridge utilizando factores de descuento 0.9 y 0.1. ¿Qué cambios observa (si algúno) y como puede explicarlos. \n",
    "  \n",
    "  Recuerde que el ambiente del puente se define con la matriz de `3x7` donde las filas 1 y 3 tienen recompensa -100 entre las columnas 2 y 6. La fila 2 corresponde a el puente, con entrada en la casilla `(2,1)` y salida en la casilla `(2,7)` con recompensa 100, como se muestra en la figura\n",
    "\n",
    "  ![bridge](https://raw.githubusercontent.com/FLAGlab/isis4222-rl/a502e264157729fcb8cc00d484e4a8e8e4734a15/week4/img/bridge.png)\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:47:45.498771Z",
     "start_time": "2024-09-09T19:47:45.303437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from assignment_agent_iteration.grid_world import EnvironmentWorld\n",
    "import pandas as pd\n",
    "\n",
    "from assignment_agent_iteration.policy_iteration import PolicyIteration\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "grid_world = EnvironmentWorld([\n",
    "    ['S'] + [' '] * 9,\n",
    "    [' '] * 10,\n",
    "    [' ', '#', '#', '#', '#', ' ', '#', '#', '#', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', '-1', ' ', ' ', ' ', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', '+1', ' ', ' ', ' ', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', ' ', ' ', ' ', ' ', ' '],\n",
    "    [' ', ' ', ' ', ' ', '#', '-1', '-1', ' ', ' ', ' '],\n",
    "    [' '] * 10,\n",
    "    [' '] * 10\n",
    "])\n",
    "\n",
    "bridge_world = EnvironmentWorld([\n",
    "    ['#', '-100', '-100', '-100', '-100', '-100', '#'],\n",
    "    ['+1', 'S', ' ', ' ', ' ', ' ', '+100'],\n",
    "    ['#', '-100', '-100', '-100', '-100', '-100', '#'],\n",
    "])\n",
    "\n",
    "print(grid_world)\n",
    "print('\\n\\n')\n",
    "print(bridge_world)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0  1  2  3  4   5   6  7  8  9\n",
      "0  SC                             \n",
      "1                                 \n",
      "2      #  #  #  #       #  #  #   \n",
      "3               #                 \n",
      "4               #  -1             \n",
      "5               #  +1             \n",
      "6               #                 \n",
      "7               #  -1  -1         \n",
      "8                                 \n",
      "9                                 \n",
      "\n",
      "\n",
      "\n",
      "    0     1     2     3     4     5     6\n",
      "0   #  -100  -100  -100  -100  -100     #\n",
      "1  +1    SC                          +100\n",
      "2   #  -100  -100  -100  -100  -100     #\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:47:49.927208Z",
     "start_time": "2024-09-09T19:47:48.754021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "policy_iterator_grid_world = PolicyIteration(grid_world)\n",
    "iterations_to_converge_grid = policy_iterator_grid_world.run_policy_iteration()\n",
    "print('Grid World Values')\n",
    "print(policy_iterator_grid_world)\n",
    "print('Grid World Policy')\n",
    "print(policy_iterator_grid_world.get_full_policy().map(lambda action: action.name if action else 'NONE'))\n",
    "print(f'Iterations to converge: {iterations_to_converge_grid}\\n')\n",
    "\n",
    "policy_iterator_bridge_world = PolicyIteration(bridge_world)\n",
    "iterations_to_converge_bridge = policy_iterator_grid_world.run_policy_iteration()\n",
    "print('Bridge World Values')\n",
    "print(policy_iterator_bridge_world)\n",
    "print('Bridge World Policy')\n",
    "print(policy_iterator_bridge_world.get_full_policy().map(lambda action: action.name if action else 'NONE'))\n",
    "print(f'Iterations to converge: {iterations_to_converge_bridge}\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid World Values\n",
      "          0         1         2         3         4         5         6         7         8         9\n",
      "0  0.192268  0.298091  0.416345  0.548492  0.685885  0.813113  0.667277  0.489809  0.438292  0.535297\n",
      "1  0.192957  0.334264  0.478574  0.654671  0.866203  1.118372  0.807745  0.572559  0.574757  0.769046\n",
      "2  0.116213       NaN       NaN       NaN       NaN  1.544084       NaN       NaN       NaN  1.099033\n",
      "3  0.055296  0.026462  0.023817  0.032569       NaN  1.923278  2.182248  2.060910  1.746832  1.395578\n",
      "4  0.027455  0.033723  0.051120  0.071865       NaN  3.415325  2.809101  2.475173  2.006513  1.571647\n",
      "5  0.046320  0.074524  0.106644  0.139814       NaN  3.770681  3.675020  2.859822  2.237047  1.738443\n",
      "6  0.088253  0.138485  0.192448  0.244485       NaN  3.821483  3.302734  2.753050  2.242061  1.790945\n",
      "7  0.134615  0.214156  0.304928  0.391780       NaN  2.493228  2.428174  2.135222  1.876962  1.589826\n",
      "8  0.159552  0.266935  0.409744  0.593576  0.828451  1.132087  1.237290  1.651327  1.481475  1.295578\n",
      "9  0.145756  0.243185  0.369423  0.525099  0.712826  0.929281  1.053353  1.260729  1.132602  1.014702\n",
      "Grid World Policy\n",
      "       0      1     2      3      4      5      6      7      8      9\n",
      "0  RIGHT  RIGHT    UP     UP     UP  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT\n",
      "1  RIGHT  RIGHT    UP   LEFT  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT\n",
      "2  RIGHT  RIGHT    UP   DOWN  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT  RIGHT\n",
      "3  RIGHT  RIGHT    UP   DOWN   DOWN   DOWN   DOWN   DOWN  RIGHT  RIGHT\n",
      "4  RIGHT  RIGHT    UP     UP     UP     UP     UP     UP  RIGHT     UP\n",
      "5   DOWN   DOWN  DOWN  RIGHT   DOWN   DOWN     UP     UP     UP     UP\n",
      "6   DOWN   LEFT    UP   DOWN   DOWN   LEFT   LEFT     UP  RIGHT     UP\n",
      "7   LEFT   LEFT    UP   DOWN   DOWN   LEFT   LEFT     UP     UP     UP\n",
      "8  RIGHT  RIGHT    UP   DOWN   DOWN   LEFT   LEFT   LEFT   LEFT   LEFT\n",
      "9   DOWN   DOWN  DOWN   DOWN   DOWN   LEFT   LEFT   LEFT   LEFT     UP\n",
      "Iterations to converge: 19\n",
      "\n",
      "Bridge World Values\n",
      "     0      1      2      3      4      5      6\n",
      "0  NaN -100.0 -100.0 -100.0 -100.0 -100.0    NaN\n",
      "1  1.0    0.0    0.0    0.0    0.0    0.0  100.0\n",
      "2  NaN -100.0 -100.0 -100.0 -100.0 -100.0    NaN\n",
      "Bridge World Policy\n",
      "      0      1   2\n",
      "0    UP   DOWN  UP\n",
      "1  DOWN   LEFT  UP\n",
      "2  DOWN  RIGHT  UP\n",
      "3  DOWN  RIGHT  UP\n",
      "4  DOWN  RIGHT  UP\n",
      "5  DOWN  RIGHT  UP\n",
      "6    UP     UP  UP\n",
      "Iterations to converge: 1\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:15:20.078495Z",
     "start_time": "2024-09-09T19:15:20.075391Z"
    }
   },
   "cell_type": "code",
   "source": "policy_iterator_grid_world.get_action((5,4))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Action.UP: 'up'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
